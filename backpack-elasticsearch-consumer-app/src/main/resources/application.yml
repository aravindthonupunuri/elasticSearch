micronaut:
  application:
    name: backpack-elasticsearch-consumer
  server:
    host: ${backpack-elasticsearch-consumer-host:localhost}
    port: 8085

  metrics:
    binders:
      web:
        enabled: false # we are using our own binder via our custom micronaut-metrics lib

lists:
  metrics:
    binders:
      http:
        enabled: true # we are using our own binder via our custom micronaut-metrics lib

jackson:
  property-naming-strategy: "SNAKE_CASE"

filter:
  server:
    order:
      lists-brave-tracing-server-filter: 100
      list-authorization-filter: 200
      registry-channel-subchannel-filter: 400
  client:
    order:
      lists-brave-tracing-client-filter: 900
      metrics-filter: 850
      resilience-client-filter: 800
      oauth-filter: 701
      oauth-key-filter: 700

logging:
  mdc:
    enabled: true
    keys:
      - profile_id
      - x-api-id

api:
  oauth:
    url: https://oauth.iam.perf.target.com
    client-id: ${id2-client-id}
    client-secret: ${id2-client-secret}
    nuid-username: ${id2-nuid-username}
    nuid-password: ${id2-nuid-password}
    id2-refresh-mins: ${id2-refresh-minutes}

elasticsearch:
  index: ${esaas-index}
  operation-timeout: 500ms # seconds, default: 1s
  httpHosts: ${esaas-primary-url} # same as esaas.primary.httpHosts
  request:
    default:
      connection-request-timeout: 200   # millis, default: 1s
      connect-timeout: 10000            # millis, default: 30s

esaas:
  nuidUser: ${esaas-nuid}
  nuidPassword: ${esaas-password}
  use-fallback: true
  primary:
    httpHosts: ${esaas-primary-url}
  backup:
    httpHosts: ${esaas-backup-url}

resilience4j:
  filter: false
  circuitbreaker:
    failure-rate-threshold: 50                      # failure rate threshold in percentage (default: 50)
    wait-duration-secs-in-open-state: 1             # time cb waits before transitioning from open to half-open (default: 60s)
    sliding-window-type: TIME_BASED                 # possible values TIME_BASED or COUNT_BASED (default: COUNT_BASED)
    sliding-window-size: 5                          # seconds for TIME_BASED, request-count for COUNT_BASED (default: 100)
    minimum-number-of-calls: 2                      # min calls required (per sliding window period) before cb calculates error rate (default: 10)
    permitted-number-of-calls-in-half-open-state: 1 # Number of permitted calls when the CircuitBreaker is half open.

backends:
  primary:
    circuit-breaker:
      enabled: true
      failure-rate-threshold: 50            # failure rate threshold in percentage
      wait-duration-secs-in-open-state: 1   # time cb waits before transitioning from open to half-open
      sliding-window-type: TIME_BASED       # possible values TIME_BASED or COUNT_BASED
      sliding-window-size: 5                # seconds for TIME_BASED, request-count for COUNT_BASED
      minimum-number-of-calls: 2            # min calls required (per sliding window period) before cb calculates error rate.
  backup:
    circuit-breaker:
      enabled: true
      failure-rate-threshold: 50            # failure rate threshold in percentage
      wait-duration-secs-in-open-state: 1   # time cb waits before transitioning from open to half-open
      sliding-window-type: TIME_BASED       # possible values TIME_BASED or COUNT_BASED
      sliding-window-size: 5                # seconds for TIME_BASED, request-count for COUNT_BASED
      minimum-number-of-calls: 2            # min calls required (per sliding window period) before cb calculates error rate.

tracing:
  zipkin:
    enabled: false
    excluded-paths: /health
    b3-propagation-suppress: true
    sample-rate-percent: 0.5
    http:
      url: "https://zipkinserver.dev.target.com"
      messageMaxBytes: 50000
    app:
      name: backpackelasticsearch
      env: stage
      region: tdc

api-key: ${api-key}

components:
  server:
    list-authorization-filter:
      enabled: false
    sanitizing-filter:
      enabled: false
    registry-channel-subchannel-filter:
      enabled: false

kafka:
  bootstrap:
    servers: ${kafka-vip}
#  ssl:
#    endpoint.identification.algorithm: ""# disable karka broker cert's hostname verification
#    keystore:
#      location: ${kafka-ssl-location}/client-keystore.jks
#      password: ${kafka-ssl-keypass}
#    truststore:
#      location: ${kafka-ssl-location}/client-truststore.jks
#      password: ${kafka-ssl-trustpass}
#      type: PKCS12
#  security:
#    protocol: ssl
  consumers:
    backpack-elasticsearch-msg-bus-consumer:
      key:
        deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value:
        deserializer: org.apache.kafka.common.serialization.ByteArrayDeserializer
    backpack-elasticsearch-dlq-consumer:
      key:
        deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value:
        deserializer: org.apache.kafka.common.serialization.ByteArrayDeserializer
  producers:
    # default is a Jackson based JSON serializer for key/value
    backpack-elasticsearch-msg-bus-producer:
      retries: 3
      retry:
        backoff:
          ms: 1000
      max:
        in:
          flight:
            requests:
              per:
                connection: 1
        block:
          ms: 2000

msgbus:
  source: backpackelasticsearch
  dlq-source: backpackelasticsearch-dlq
  kafka:
    consumer:
      enabled: true
    producer:
      enabled: true
    dlqconsumer:
      enabled: true
    dlqproducer:
      enabled: true
    topic: ${kafka-msgbus-topic}
    consumer-group: lists-msg-bus-consumer
    consumer-batch-size: 10
    dlq-topic: ${kafka-dlq-topic}
    dlq-consumer-group: lists-dlq-consumer
    dlq-event-retry-interval-secs: 1
    dlq-max-event-retry-count: 2
    dlq-consumer-batch-size: 10

kafka-sources:
  allow:
    - backpack-registry
    - backpackelasticsearch

endpoints:
  health:
    enabled: true
    sensitive: false
    elasticsearch:
      rest.high.level.enabled: false # disable default elastic health indicator and use custom indicator instead

